{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mgzxn85UdDlq"
   },
   "source": [
    "# Section 1: Introduction to High-Performance Computing on Multi-CPU cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7t6iWKto4fo6"
   },
   "source": [
    "So far, we have been writing algorithms that are executed step-by-step.\n",
    "\n",
    "Then, every line we write, the Python Interpreted converts it into Machine code and such instructions are executed by one single CPU processor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfKE9JGivEgV"
   },
   "source": [
    "## 1.1 What's a CPU?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpitZqS74ZoA"
   },
   "source": [
    "Its names comes from **C**entral **P**rocessing **U**nit.\n",
    "\n",
    "It is the responsible for executing every instruction that it is given, handling the processing of _logical_ and _mathematical_ operations.\n",
    "\n",
    "In short, the main tasks for a CPU are:\n",
    "+ Reading each instruction from memory. The CPU and RAM constantly work together. This is also called reading from memory.\n",
    "+ Decoding or translating instructions in a way it can understand (Machine code).\n",
    "+ Executing and carrying out the given instructions.\n",
    "+ Storying the result of an execution back to memory (writing to memory).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wY_Y-EII119L"
   },
   "source": [
    "## 1.2. The power of low-level compilers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwTa-cTZ5x9G"
   },
   "source": [
    "### 1.2.1. Just-In-Time Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZRpVOTfO7uZ"
   },
   "source": [
    "![](imgs/slides_d2/028.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOfyaGF-5362"
   },
   "source": [
    "+ Just-in-time (JIT) compilation is a way of executing computer code that involves compilation during *execution of a program* rather than before execution. \n",
    "\n",
    "+ JIT compilation combines the speed of compiled code with the versability and flexibility of interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qKparhL58JW"
   },
   "source": [
    "### 1.2.2. Numba to the rescue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XnFUZKhU57uf"
   },
   "source": [
    "#### 1.2.2.1. What's Numba?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLPXft4VOyTP"
   },
   "source": [
    "![](imgs/slides_d2/030.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L51fVYEKS1XW"
   },
   "source": [
    "Numba is a High-Performance compiler for Python. It translates a subset of Python and NumPy functions into low-level code for speed.\n",
    "\n",
    "Numba is best used for loops, numpy arrays operations and functions.\n",
    "\n",
    "Some of its properties are:\n",
    "1. Compile Python code into an intermediate code readable for LLVM (Low Level Virtual Machine).\n",
    "2. Vectorize functions.\n",
    "3. Run functions in parallel both Multi-CPU and GPU cores.\n",
    "4. Easy to use thanks to decorators.\n",
    "\n",
    "Here, we want to gain speed without having to change many lines in our programs. \n",
    "\n",
    "Due to Python is a high-level language, we will try to generate a low-level intermediate language through compilation ðŸ’¡.\n",
    "\n",
    "Let's see how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8uPvEug58Zn"
   },
   "source": [
    "#### 1.2.2.2. Numba's `@decorators`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZDU5JO6P9n2"
   },
   "source": [
    "Remember : Decorators allow us to modify functions and extend their use. \n",
    "\n",
    "We can compile our Python code by using Numba's decorators. In fact, when we call a Numba-decorated function _it is compiled to machine code \"just-in-time\"_ for execution.\n",
    "\n",
    "In this way, our code can really run close to machine code speed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSPEXAJC6Fwh"
   },
   "source": [
    "#### 1.2.2.3. `nopython` mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYKxRDR36eRp"
   },
   "source": [
    "The Numba @jit decorator fundamentally operates in two compilation modes, nopython mode and object mode.\n",
    "\n",
    "If we define the `@jit` decorator with the parameter `nopython=True`, the decorated function will run enterily without the involvement of the Python Interpreter.\n",
    "\n",
    "This is the recommended and best-practice way.\n",
    "\n",
    "(_source: [Numba](https://numba.pydata.org/)_).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iK1siPzGxPCm"
   },
   "source": [
    "##### 1.2.2.3.1. Example: Using a JIT decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJh1xael7mCC"
   },
   "source": [
    "Let's compare a compiled version of my_sum with the one that executed by the Python Interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltRYWK97xSHs"
   },
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2A_z1HZxmIW"
   },
   "outputs": [],
   "source": [
    "def my_py_sum(x):\n",
    "    result = 0\n",
    "    for i in range(len(x)):\n",
    "        result = result + x[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yv0-JmaexN4k"
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def my_njit_sum(x):\n",
    "    result = 0\n",
    "    for i in range(len(x)):\n",
    "        result = result + x[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwjwtVnLxsv1"
   },
   "outputs": [],
   "source": [
    "# generating data\n",
    "x = np.random.randint(10, size=100_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBmfduNK74jb"
   },
   "source": [
    "Let's compare execution times !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Me0lGEOyxp8W",
    "outputId": "def67ac2-d8d9-4817-d832-1bcac47a34f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 5: 16.6 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit my_py_sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h6mJznuBx2VW",
    "outputId": "602ff7d7-2f7c-420d-916f-af5809e30a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 11276.69 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 5: 12.5 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit my_njit_sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zk4nUC0E6FoL"
   },
   "source": [
    "#### 1.2.2.4. Exercise (`nopython` mode)\n",
    "\n",
    "1. Given two methods `py_sum(x,y)` and `np.sum(x,y)`, creates a method `numba_sum(x,y)` that computes the L1-distance of each element of two input arrays `x` and `y` with lengths $N$ (i.e., $\\sum_{i=0}^{N-1} |x_i - y_i|$). \n",
    "\n",
    "   Be sure of _using Python's built-in functions only_ for the `numba_sum(x,y)` function. \n",
    "   \n",
    "   Finally, measure their computational time for every method and compare them!\n",
    "\n",
    "2. **(Bonus):** Run 10 repetitions of the same computation, store those computation times, and show the mean and standard deviation for `py_sum(x)`, `np.sum(x)`, and`numba_sum(x)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhk-GAJ0L7b_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AqlWHfKsMtPR"
   },
   "outputs": [],
   "source": [
    "# Generating 1M random numbers from (0,9).\n",
    "x = np.random.randint(10, size=1_000_000) \n",
    "y = np.random.randint(10, size=1_000_000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sh475HwNL5Fi"
   },
   "outputs": [],
   "source": [
    "def py_sum(x, y):\n",
    "  N = len(x)\n",
    "  # creating a list of N elements\n",
    "  result = 0 #[ 0 for _ in range(len(N))]\n",
    "  for i in range(N):\n",
    "    result = result + abs(x[i] - y[i])\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__rYlw-cMSCd"
   },
   "outputs": [],
   "source": [
    "# add a decorator here !\n",
    "def numba_sum(x, y):\n",
    "  N = len(x)\n",
    "  result = 0.\n",
    "  for i in range(N):\n",
    "    result = result + abs(x[i] - y[i])\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLbasY9YM2Hz"
   },
   "source": [
    "Reminder: `time.time()` returns the current time (in seconds) of its execution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g5YI_rU-cnUe"
   },
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZinMnUNMlJ4"
   },
   "outputs": [],
   "source": [
    "exec_time_python = time()\n",
    "py_sum(x,y)\n",
    "exec_time_python = time() - exec_time_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RvBMEQ2wNHrl"
   },
   "outputs": [],
   "source": [
    "exec_time_numpy = time()\n",
    "# write a numpy function here !\n",
    "exec_time_numpy = time() - exec_time_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcE3woj8NOgo"
   },
   "outputs": [],
   "source": [
    "exec_time_numba = time()\n",
    "# execute your compiled numba function here!\n",
    "exec_time_numba = time() - exec_time_numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuerrXWONiTI"
   },
   "outputs": [],
   "source": [
    "# print every execution time here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1W8ufITNnc_"
   },
   "source": [
    "Any conclusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRXmVZg_jYXk"
   },
   "source": [
    "#### 1.2.2.4. Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDG2GJijjbXN"
   },
   "outputs": [],
   "source": [
    "# your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXiUDQ2W6Flv"
   },
   "source": [
    "#### 1.2.2.5. [DELETE] Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97a5kzdQ6khA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXb04Lfp2Rgx"
   },
   "outputs": [],
   "source": [
    "# Generating 1M random numbers from (0,9).\n",
    "x = np.random.randint(10, size=1_000_000) \n",
    "y = np.random.randint(10, size=1_000_000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RLTRiCT6c62"
   },
   "outputs": [],
   "source": [
    "def py_sum(x, y):\n",
    "    N = len(x)\n",
    "    # creating a list of N elements\n",
    "    result = 0 #[ 0 for _ in range(len(N))]\n",
    "    for i in range(N):\n",
    "        result = result + abs(x[i] - y[i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLwaRb2O2UsM"
   },
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def numba_sum(x, y):\n",
    "    N = len(x)\n",
    "    result = 0.\n",
    "    for i in range(N):\n",
    "        result = result + abs(x[i] - y[i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NY9qSGB76rqP",
    "outputId": "6b116180-22ce-4dab-fb5c-4016d8a2e3cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3301174"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_sum(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTCA8GU_Ph9u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPBITvwY6riA"
   },
   "outputs": [],
   "source": [
    "exec_time_python = time()\n",
    "py_sum(x,y)\n",
    "exec_time_python = time() - exec_time_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAxkdL9t65BG"
   },
   "outputs": [],
   "source": [
    "exec_time_numpy = time()\n",
    "np.sum(np.abs(x-y))\n",
    "exec_time_numpy = time() - exec_time_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgKfeHTT7Dvn"
   },
   "outputs": [],
   "source": [
    "exec_time_numba = time()\n",
    "numba_sum(x,y)\n",
    "exec_time_numba = time() - exec_time_numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tuo4VpZY7HGZ",
    "outputId": "2e34f5d7-7f80-4374-a44f-b741170aeefc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python built-in sum: 0.435711145401001\n",
      "Numpy sum          : 0.008499622344970703\n",
      "Numba compiled sum : 0.11591291427612305\n"
     ]
    }
   ],
   "source": [
    "print(\"Python built-in sum:\", exec_time_python)\n",
    "print(\"Numpy sum          :\", exec_time_numpy )\n",
    "print(\"Numba compiled sum :\", exec_time_numba )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RE7KEALnQHle"
   },
   "source": [
    "Conclusions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwuoRfj96Fjn"
   },
   "source": [
    "**Solution Exercise #2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NbNghStC7fmP"
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "times_numpy_sum  = np.zeros(shape=10)\n",
    "times_python_sum = np.zeros(shape=10)\n",
    "times_njit_sum   = np.zeros(shape=10)\n",
    "\n",
    "for it in range(10):\n",
    "    # python func.\n",
    "    t = time()\n",
    "    my_sum(x)\n",
    "    t = time() - t\n",
    "    times_python_sum[it] = t \n",
    "\n",
    "    # njit func.\n",
    "    t = time()\n",
    "    my_sum_njit(x)\n",
    "    t = time() - t\n",
    "    times_njit_sum[it] = t \n",
    "\n",
    "    # numpy func.\n",
    "    t = time()\n",
    "    np.sum(x)\n",
    "    t = time() - t\n",
    "    times_numpy_sum[it] = t \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1hKLGKj7hs4",
    "outputId": "e7f36133-bfb8-4f6a-c3d8-efa5c6b3d006"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.294348  , 0.28803158, 0.29592371, 0.28964925, 0.29641986,\n",
       "        0.29230523, 0.31979561, 0.5130136 , 0.29662228, 0.29207444]),\n",
       " array([0.00105548, 0.00105405, 0.00105095, 0.00105071, 0.00133204,\n",
       "        0.00105929, 0.00122118, 0.00103569, 0.00104952, 0.00105119]),\n",
       " array([0.00078368, 0.00070119, 0.00065613, 0.0007031 , 0.0010004 ,\n",
       "        0.00068808, 0.00089598, 0.00065494, 0.00080657, 0.00067949]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_python_sum, times_njit_sum, times_numpy_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "glT6xYWl7lpP",
    "outputId": "f3a269c9-868d-42e3-f745-f58b8d9fcdfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SU(python, njit) mean=292.555\tstd=69.656\n",
      "SU(numpy, njit)  mean=0.688\tstd=0.052\n"
     ]
    }
   ],
   "source": [
    "speedup_python = (times_python_sum/times_njit_sum)\n",
    "speedup_numpy = (times_numpy_sum/times_njit_sum)\n",
    "\n",
    "mean_py = np.mean(speedup_python)\n",
    "std_py  = np.std(speedup_python)\n",
    "mean_np = np.mean(speedup_numpy)\n",
    "std_np  = np.std(speedup_numpy)\n",
    "\n",
    "print(\"SU(py, njit) mean=%.3f\\tstd=%.3f\" % (mean_py, std_py)\n",
    "print(\"SU(np, njit) mean=%.3f\\tstd=%.3f\" % (mean_np, std_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxabQP3SWINY"
   },
   "source": [
    "We already improved **a lot** the computation time of our function!.\n",
    "\n",
    "As you saw, you only need to add a _decorator_ to improve the performance and by compiling Python instructions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcZak-sh7GFV"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yH8rCoqY-KFd"
   },
   "source": [
    "## 1.3. Computational strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBujptjD7Y-_"
   },
   "source": [
    "### 1.3.1. Serialism, Concurrency and Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Dl9Jm-YOtoH"
   },
   "source": [
    "![](imgs/slides_d2/039.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abW_7ilc_hKF"
   },
   "source": [
    "*Serialism* is the traditional way of doing computing: the processor or the system will be executing just one work by time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vd9QrWul_ONe"
   },
   "source": [
    "We can distinguish between *concurrency* and *parallelism* based on the next two definitions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJrVPTbx_F61"
   },
   "source": [
    "**Definition 1.** \n",
    "\n",
    "Concurrency is a property of a program (at design level) where two or more tasks can be in progress simultaneously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnon5wWd_cw6"
   },
   "source": [
    "**Definition 2.**\n",
    "\n",
    "Parallelism is a run-time property where two or more tasks are being executed simultaneously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Js3lP7SH_0mQ"
   },
   "source": [
    "Let $C$ and $P$ be concurrency and parallelism, respectively, then $P \\subset C$. \n",
    "\n",
    "Thus, parallelism requiers concurrency, but concurrency does not require parallelism.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oI7iW9FR__fF"
   },
   "source": [
    "### 1.3.2. Types of parallelisms\n",
    "\n",
    "**Parallel computing** is the act of solving a problem of size $n$ by dividing its domain into $k \\geq 2$ (with $k \\in \\mathcal{N}$) parts and solving them with $p$ physical processors, simultaneously.\n",
    "\n",
    "Let $P_{D}$ be a problem with domain $D$. If $P_{D}$ is parallelizable, then $D$ can be decomposed into $k$ sub-problems:\n",
    "\n",
    "$D = d_1 + d_2 + ... + d_k = \\sum_{i=1}^k d_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxsMD9KrBBA-"
   },
   "source": [
    "#### 1.3.2.1. Definition: Data- and Task-parallel problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PW72uw8AGQe"
   },
   "source": [
    "$P_{D}$ is a **data-parallel problem** if $D$ is composed of data elements and solving the problem requires applying a kernel function $f()$ to the whole domain:\n",
    "\n",
    "$f(D) = f(d_{1}) + f(d_{2}) + ... + f(d_{k}) = \\sum_{i=1}^k f(d_i)$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrH52J7wAS_O"
   },
   "source": [
    "In contrast, $P_D$ is a **task-parallel problem** if $D$ is composed of functions and solving the problem requires applying each function to a common stream of data $S$:\n",
    "\n",
    "$D(S) = d_1(S) + d_2(S) + ... + d_k(S) = \\sum_{i=1}^k d_i(S)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5b6d2fNDkfo"
   },
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6P5A4cZDpsS"
   },
   "source": [
    "Let $D$ be a 1D-array with $n$ components. Then, we can define $k = \\frac{n}{N}$ as the amount of chunks of data to be analyzed for each core. \n",
    "\n",
    "Thus, we can run in parallel an algorithm such that each core works in a partition of the original data $D = d_1 + d_2 + \\dots + d_k$, with $N$ the amount of cores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InEQ0yrBOopQ"
   },
   "source": [
    "![](imgs/slides_d2/044.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ky21ffu_AUZF"
   },
   "source": [
    "#### 1.3.2.2. Which types of problems are better for multithread computing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjS82ndnBOyH"
   },
   "source": [
    "**Data-parallel problems are ideal candidates for the GPU or multi-core CPUs beacuse each thread executes the same instructions but on different data**. \n",
    "\n",
    "On the other hand, tasks-parallel problems are best suited for the CPU since they enable the execution of many tasks with adaptable memory access patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81WfWYOz7Lj2"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QiAmRYNBazA"
   },
   "source": [
    "## 1.4. Parallel computing with Python! (ft. Numba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPL0xj87GnYP"
   },
   "source": [
    "In this section we will use the same python ecosystem but we will include Numba for Just-In-Time compilation plus multithreading on CPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoCqCf3-Ohqo"
   },
   "source": [
    "![](imgs/slides_d2/046.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2SI-WQ0COaQ"
   },
   "source": [
    "### 1.4.1. The magic trick: Numba's Parallel range (`prange`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V05yZf1bCq6h"
   },
   "source": [
    "Let's use `prange`! It's like Python's `range` function but it runs in **p**arallel ðŸ¤¯.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdFuzaHxC5PH"
   },
   "source": [
    "#### 1.4.1.1. Example (`prange`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_ucf5vhOUsq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hrtvm7MtORi2"
   },
   "outputs": [],
   "source": [
    "def my_serial_count(N):\n",
    "    result = 0\n",
    "    for i in range(N):\n",
    "        result += 1 \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPbgXcurOVSV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit, prange, set_num_threads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JmdGySM2OE5X"
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True, parallel=True)\n",
    "def my_parallel_count(N):\n",
    "    result = 0\n",
    "    for i in prange(N):\n",
    "        result += 1 \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUdYclSYOYvG",
    "outputId": "26634c04-0a21-4573-d874-1b1d596d7466"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_serial_count(N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VuTldQpXObHG",
    "outputId": "a9c4f747-59e7-4ea7-8fb9-f551fcb71b20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_parallel_count(N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6LBif09-Od9Y",
    "outputId": "4be4e87e-ad63-44b0-b60b-7c6a7f5827ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 5: 62.7 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit my_serial_count(N=1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S942GK3gOgp4",
    "outputId": "6962d077-9c67-401e-829a-cbab386ad8b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 448.88 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 5: 2.7 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit my_parallel_count(N=1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfyQX9P872Pa"
   },
   "source": [
    "#### 1.4.1.2. Exercise\n",
    "\n",
    "Improve our function `my_serial_sum(x)` and make it run in multiple cores via `@parallel`. Measure the computation time and calculate the _speed-up_ compared with our previous version with `@njit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCqbMc3FDhiI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import prange, jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8bE9ws_Dkyy"
   },
   "outputs": [],
   "source": [
    "# Generating 1M random numbers from (0,9).\n",
    "x = np.random.randint(10, size=1_000_000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9N41N2KDl4v"
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def my_serial_sum(x):\n",
    "    N = len(x)\n",
    "    result = 0\n",
    "    for i in prange(N):\n",
    "        result = result + x[i]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RR4wi2mE767Y"
   },
   "source": [
    "#### 1.4.1.3. Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_MRKw7O60-CD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import prange, jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdWy5Wu00_By"
   },
   "outputs": [],
   "source": [
    "# Generating 1M random numbers from (0,9).\n",
    "x = np.random.randint(10, size=1_000_000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XYTBZrv_1I9Q"
   },
   "outputs": [],
   "source": [
    "def my_py_sum(x):\n",
    "    N = len(x)\n",
    "    result = 0\n",
    "    for i in prange(N):\n",
    "        result = result + x[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDBxx_ea1Bhk"
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def my_serial_sum(x):\n",
    "    N = len(x)\n",
    "    result = 0\n",
    "    for i in prange(N):\n",
    "        result = result + x[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVfpr6rN2AzZ"
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True, parallel=True)\n",
    "def my_parallel_sum(x):\n",
    "    N = len(x)\n",
    "    result = 0\n",
    "    for i in prange(N):\n",
    "        result = result + x[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "onXJdV9AD8d5",
    "outputId": "b66ff564-8b0e-4db9-acb1-e71a9ec25b90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 5: 273 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit my_serial_sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tt2A_4P_2JeJ",
    "outputId": "47bf37c4-f3c8-43b8-f571-2c7f9f46b6e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 1152.68 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 5: 317 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit my_parallel_sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MN8kDfUbEEML"
   },
   "source": [
    "#### 1.4.1.4. Bonus exercises\n",
    "\n",
    "Measure the computation time of each version (i.e., pure Python, NumPy, `nopython` compiled, and `parallel`) for 10 repetitions.\n",
    "\n",
    "Print the mean and standard deviation of the speed-up for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VEhE8Jd8Lpo"
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "times_numpy_sum  = np.zeros(shape=10)\n",
    "times_python_sum = np.zeros(shape=10)\n",
    "times_njit_sum   = np.zeros(shape=10)\n",
    "times_parallel_sum = np.zeros(shape=10)\n",
    "\n",
    "for it in range(10):\n",
    "    # python func.\n",
    "    t = time()\n",
    "    my_py_sum(x)\n",
    "    t = time() - t\n",
    "    times_python_sum[it] = t \n",
    "\n",
    "    # numpy func.\n",
    "    t = time()\n",
    "    np.sum(x)\n",
    "    t = time() - t\n",
    "    times_numpy_sum[it] = t \n",
    "\n",
    "    # njit func.\n",
    "    t = time()\n",
    "    my_serial_sum(x)\n",
    "    t = time() - t\n",
    "    times_njit_sum[it] = t\n",
    "\n",
    "    # nopython=True, parallel=True\n",
    "    t = time()\n",
    "    my_parallel_sum(x)\n",
    "    t = time() - t\n",
    "    times_parallel_sum[it] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvnF5bOe8pFI",
    "outputId": "ecc910ef-6d7a-4082-cf14-62d38044c4db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SU(py, p)   mean=230.761\tstd=44.310\n",
      "SU(np, p)   mean=1.631\tstd=0.369\n",
      "SU(njit, p) mean=1.071\tstd=0.134\n"
     ]
    }
   ],
   "source": [
    "speedup_python = (times_python_sum/times_parallel_sum)\n",
    "speedup_numpy = (times_numpy_sum/times_parallel_sum)\n",
    "speedup_njit = (times_njit_sum/times_parallel_sum)\n",
    "\n",
    "mean_py = np.mean(speedup_python)\n",
    "std_py  = np.std(speedup_python)\n",
    "mean_np = np.mean(speedup_numpy)\n",
    "std_np  = np.std(speedup_numpy)\n",
    "mean_njit = np.mean(speedup_njit)\n",
    "std_njit  = np.std(speedup_njit)\n",
    "\n",
    "print(\"SU(py, p)   mean=%.3f\\tstd=%.3f\" % (mean_py, std_py))\n",
    "print(\"SU(np, p)   mean=%.3f\\tstd=%.3f\" % (mean_np, std_np))\n",
    "print(\"SU(njit, p) mean=%.3f\\tstd=%.3f\" % (mean_njit, std_njit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTlKqwZf7O3e"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIe1mBy1EpYB"
   },
   "source": [
    "## 1.5. Practical Session (HPC): Measuring Speed-up with Numba on  Multi-CPU cores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAyN30SFE1VB"
   },
   "source": [
    "### 1.5.1. Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJ28hYoo89gI"
   },
   "source": [
    "1. Create two vectors `x` and `y` that contain $N$ random values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtD_NwShWSc8"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ksl4q18t9I6R"
   },
   "outputs": [],
   "source": [
    "# your code here :) \n",
    "# Hint: Usec an np.random.randint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3j5Y4CEN9LtY"
   },
   "source": [
    "2. Compute the distance $d$ between the two vectors $x$ and $y$ with length $N$ such that $d(x,y) = \\sqrt{(x_1 - y_1)^2+(x_2 - y_2)^2+ \\dots + (x_N - y_N)^2}$.\n",
    "\n",
    "Use pure python for this (e.g., `import math` for square root computation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9sW5Whx9NTb"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jscIZlj79Oqp"
   },
   "source": [
    "3. Make a copy of such function and make it `@jit(nopython=True)` and parallel via `@jit(nopython=True, parallel=True)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSwm-PrgWnM8"
   },
   "outputs": [],
   "source": [
    "from numba import jit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXXNdSdC9UMg"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkK8faaY9R80"
   },
   "source": [
    "4. Execute these three functions and save their execution times across 10 repetitions. \n",
    "\n",
    "   Compute the speed-ups as follows:\n",
    "   + Python method vs Parallel:  $speedup_{(py, parallel)} = \\bar{t}_{py} / \\bar{t}_{p}$.\n",
    "   + Compiled method vs Parallel:  $speedup_{(njit, parallel)} = \\bar{t}_{njit} / \\bar{t}_{p}$.\n",
    "\n",
    "  Note: $\\bar{t}_{i,j}$ is the average execution time between methods $i$ and $j$.\n",
    "\n",
    "  Print both speed-ups (mean and std).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nM6oXMzWWAM"
   },
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvRrWHD7V8A4"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAfdxIfA9Q_Z"
   },
   "source": [
    "\n",
    "5. Repeat this same procedure but change the length of the vectors $N$ (e.g., `l_N = [10, 100, 1000, 10000, 100000, 1000000]`). As a recommendation, you can store the computational times into a matrix of `n_rep` columns and `l_N` rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IX2eSKPUWC5Z"
   },
   "outputs": [],
   "source": [
    "l_N = [10, 100, 1000, 10000, 100000, 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lsqOWAM89Q1o"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feJXXhbW9bF6"
   },
   "source": [
    "6. Make a plot that shows how the speed-up changes when the size of the problem increases (i.e., $N$). Do this for $Speedup_{py,p}$ and $Speedup_{njit,p}$, *separately*. \n",
    "\n",
    "   Use `plt.errorbar(l_N, mean_speedup, std_speedup)` to show your results. For more information about errorbar, check [this](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.errorbar.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wef6hxZNWOFL"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Nqrp0K4WMZK"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAPx5Z0BTHwG"
   },
   "source": [
    "7. Finally, plot both speed-up. To see the differences, add `plt.loglog()` and `\n",
    "plt.axhline(1, color='k', alpha=0.3, ls='--')` at the end of each cell. Your plots will change both x- and y-axis to log-scale. What can we conclude from these results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJiIyyvQ9ac6"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "plt.loglog()\n",
    "plt.axhline(1, color='k', alpha=0.3, ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_I3TeUyFFATC"
   },
   "source": [
    "### 1.5.2. Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vC9zknqvFCcX"
   },
   "source": [
    "### 1.5.2. [DELETE] Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOvJDeFZVdBV"
   },
   "source": [
    "1. Create two vectors `x` and `y` that contain $N$ random values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcycG6NFHnrU"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWgaxdzGHePT"
   },
   "outputs": [],
   "source": [
    "N = 1_000_000\n",
    "x = np.random.randint(1000, size=N)/1000.\n",
    "y = np.random.randint(1000, size=N)/1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIrM5jJGVdBW"
   },
   "source": [
    "2. Compute the euclidean distance between the two vectors: $d(a,b) = \\sqrt{(x_1 - y_1)^2+(x_2 - y_2)^2+ \\dots + (x_N - y_N)^2}$.\n",
    "\n",
    "Use pure python for this (e.g., `import math` for square root computation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJYk22rxHu_k"
   },
   "outputs": [],
   "source": [
    "def py_euclidean_distance(x,y):\n",
    "    distance = 0.\n",
    "    for i in range(len(x)):\n",
    "        distance = distance + (x[i]-y[i])**2\n",
    "    return distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8etGhOfVdBW"
   },
   "source": [
    "3. Make a copy of such function and make it `jit(nopython=True)` and parallel via `@jit(nopython=True, parallel=True)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNxyORw3IyrU"
   },
   "outputs": [],
   "source": [
    "from numba import jit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5XRFDJZIscU"
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def njit_euclidean_distance(x,y):\n",
    "    distance = 0.\n",
    "    for i in range(len(x)):\n",
    "        distance = distance + (x[i]-y[i])**2\n",
    "    return distance \n",
    "\n",
    "@jit(nopython=True, parallel=True)\n",
    "def parallel_euclidean_distance(x,y):\n",
    "    distance = 0.\n",
    "    for i in prange(len(x)):\n",
    "        distance = distance + (x[i]-y[i])**2\n",
    "    return distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bjhMAKyKjwG"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqTc4FbpVdBX"
   },
   "source": [
    "4. Execute all these functions and saves their execution times for 10 repetitions. \n",
    "\n",
    "   Compute the speed-ups as follows:\n",
    "   + Python method vs Parallel:  $speed-up_{py, p} = \\bar{time}_{py} / \\bar{time}_{p}$.\n",
    "   + Compiled method vs Parallel:  $speed-up_{njit, p} = \\bar{time}_{njit} / \\bar{time}_{p}$.\n",
    "\n",
    "  Note: $\\bar{time}_{i,j}$ is the average execution time between methods $i$ and $j$.\n",
    "\n",
    "  Print both speed-ups (mean and std).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8foP_HySJLA0"
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "exec_times = np.zeros(shape=(3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEfixqN5Jv_l"
   },
   "outputs": [],
   "source": [
    "my_methods = [\n",
    "    py_euclidean_distance, njit_euclidean_distance, parallel_euclidean_distance\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PP7dK9F6JRl0",
    "outputId": "2bd1ee16-4b1e-47f6-8e65-abfb3415b4d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(my_methods)):\n",
    "    f = my_methods[i]\n",
    "    for j in range(10):\n",
    "        t = time()\n",
    "        f(x,y)\n",
    "        t = time()-t\n",
    "        exec_times[i,j] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exvhM8nmKxfF",
    "outputId": "710aee3e-4a59-435e-cb6a-80596034928a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64537978, 0.63093066, 0.79584622, 0.80611014, 0.76738954,\n",
       "        0.6186738 , 0.6139524 , 0.598382  , 0.61105275, 0.63395953],\n",
       "       [0.11797428, 0.00234175, 0.0022707 , 0.00217056, 0.00214028,\n",
       "        0.00212193, 0.00211096, 0.00215507, 0.00222754, 0.00212765],\n",
       "       [0.53871512, 0.00181937, 0.00161648, 0.0013535 , 0.00119114,\n",
       "        0.00110722, 0.00104785, 0.00099158, 0.00096893, 0.00097132]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSowCOW_KZDO",
    "outputId": "a99b4bde-0057-4db2-9ce6-42ac9bd73e8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed-up(pu, p) = [  1.19799826 346.78482506 492.33348083 595.57354236 644.24839872\n",
      " 558.76528854 585.91649602 603.46140899 630.6449311  652.68016691]\n",
      "Speed-up(njit, p) = [  1.19799826 346.78482506 492.33348083 595.57354236 644.24839872\n",
      " 558.76528854 585.91649602 603.46140899 630.6449311  652.68016691]\n"
     ]
    }
   ],
   "source": [
    "speedup_py = exec_times[0]/exec_times[-1]\n",
    "speedup_njit = exec_times[1]/exec_times[-1]\n",
    "print(\"Speed-up(pu, p) =\", speedup_py)\n",
    "print(\"Speed-up(njit, p) =\", speedup_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7czKExuwOBKY"
   },
   "outputs": [],
   "source": [
    "mean_speedup_py = np.mean(speedup_py)\n",
    "std_speedup_py = np.std(speedup_py)\n",
    "mean_speedup_njit = np.mean(speedup_njit)\n",
    "std_speedup_njit = np.std(speedup_njit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nPwAL-nOTkA",
    "outputId": "89e2990c-c471-48e1-ebff-350ad9575549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed-up(pu, p)   = mean:511.16\tstd:190.51\n",
      "Speed-up(njit, p) = mean:1.69\tstd:0.59\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed-up(pu, p)   = mean:%.2f\\tstd:%.2f\" % (mean_speedup_py, std_speedup_py))\n",
    "print(\"Speed-up(njit, p) = mean:%.2f\\tstd:%.2f\" % (mean_speedup_njit, std_speedup_njit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDkeYhjvVdBY"
   },
   "source": [
    "\n",
    "5. Repeat this same procedure but change the length of the vectors $N$ (e.g., `l_N = [10, 100, 1000, 10000, 100000, 1000000]`). As a recommendation, you can store the computational times into a matrix of `n_rep` columns and `l_N` rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQTvPCc0P3BR"
   },
   "outputs": [],
   "source": [
    "l_N = [10, 100, 1000, 10000, 100000, 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvs1lI2mPskH"
   },
   "outputs": [],
   "source": [
    "exec_times_N = np.zeros(shape=(3,10,len(l_N)))\n",
    "for i_N in range(len(l_N)):\n",
    "    # generating arrays\n",
    "    N = l_N[i_N]\n",
    "    x = np.random.randint(1000, size=N)/1000.\n",
    "    y = np.random.randint(1000, size=N)/1000.\n",
    "\n",
    "    for i in range(len(my_methods)):\n",
    "        f = my_methods[i]\n",
    "        for j in range(10):\n",
    "            t = time()\n",
    "            f(x,y)\n",
    "            t = time()-t\n",
    "            exec_times_N[i,j,i_N] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2T7H3ZrQYfq",
    "outputId": "041303eb-1222-4bdc-e4b8-270616359bc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10, 6)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_times_N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "okUp655tQ1aX",
    "outputId": "cc4bf4dd-af40-4f08-87df-b0f0c7ff6f53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 6), (6,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_speed_up = exec_times_N[0,:,:] / exec_times_N[1,:,:]\n",
    "py_speed_up.shape, np.mean(py_speed_up, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5uH-bQfQbmx"
   },
   "outputs": [],
   "source": [
    "py_speed_up = exec_times_N[0,:,:] / exec_times_N[2,:,:]\n",
    "py_mean_su = np.mean(py_speed_up, axis=0)\n",
    "py_std_su = np.std(py_speed_up, axis=0)\n",
    "\n",
    "njit_speed_up = exec_times_N[1,:,:] / exec_times_N[2,:,:]\n",
    "njit_mean_su = np.mean(njit_speed_up, axis=0)\n",
    "njit_std_su = np.std(njit_speed_up, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1gOpu_YRqe1",
    "outputId": "8e284df9-f2c8-492a-d679-18bc11dd6f1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.36849213e-05, 1.93119049e-05, 7.67230988e-03, 1.13010406e-04,\n",
       "        2.19345093e-03, 1.81078911e-03],\n",
       "       [4.29153442e-06, 3.57627869e-06, 2.16960907e-05, 1.43051147e-05,\n",
       "        9.34600830e-05, 1.02758408e-03],\n",
       "       [3.09944153e-06, 3.33786011e-06, 4.29153442e-06, 1.19209290e-05,\n",
       "        8.58306885e-05, 1.00708008e-03],\n",
       "       [3.09944153e-06, 3.09944153e-06, 3.81469727e-06, 1.19209290e-05,\n",
       "        8.17775726e-05, 9.85860825e-04],\n",
       "       [2.86102295e-06, 3.33786011e-06, 4.05311584e-06, 1.19209290e-05,\n",
       "        9.01222229e-05, 9.52959061e-04],\n",
       "       [3.09944153e-06, 3.09944153e-06, 4.05311584e-06, 1.16825104e-05,\n",
       "        8.05854797e-05, 9.41276550e-04],\n",
       "       [3.09944153e-06, 3.33786011e-06, 3.81469727e-06, 1.21593475e-05,\n",
       "        8.10623169e-05, 8.91923904e-04],\n",
       "       [3.33786011e-06, 3.33786011e-06, 4.05311584e-06, 1.16825104e-05,\n",
       "        8.10623169e-05, 8.94069672e-04],\n",
       "       [3.09944153e-06, 3.09944153e-06, 4.05311584e-06, 1.19209290e-05,\n",
       "        8.32080841e-05, 8.93592834e-04],\n",
       "       [3.09944153e-06, 3.33786011e-06, 3.81469727e-06, 1.19209290e-05,\n",
       "        8.05854797e-05, 9.03606415e-04]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_times_N[2,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ov7m_GBJVdBY"
   },
   "source": [
    "6. Make a plot that shows how the speed-up changes when the size of the problem increases (i.e., $N$). Do this for $Speedup_{py,p}$ and $Speedup_{njit,p}$, *separately*. \n",
    "\n",
    "   Use `plt.errorbar(l_N, mean_speedup, std_speedup)` to show your results. For more information about errorbar, check [this](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.errorbar.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "BDnJP4ksRXbL",
    "outputId": "266df536-ca5c-442a-fb92-c71761090205"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'N (problem size)')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(6,4))\n",
    "ax.errorbar(l_N, py_mean_su, py_std_su, label='py') \n",
    "ax.set_ylabel(\"Speedup\")\n",
    "ax.set_xlabel(\"N (problem size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "SaWX1xk9SchQ",
    "outputId": "3ad0ba4f-2419-44cf-fc78-307fa0d98279"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'N (problem size)')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(6,4))\n",
    "ax.errorbar(l_N, njit_mean_su, njit_std_su, label='py') \n",
    "ax.set_ylabel(\"Speedup\")\n",
    "ax.set_xlabel(\"N (problem size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3V95HHmDVdBZ"
   },
   "source": [
    "7. Finally, plot both speed-up. To see the differences, add `plt.loglog()` and `\n",
    "plt.axhline(1, color='k', alpha=0.3, ls='--')` at the end of each cell. Your plots will change both x- and y-axis to log-scale. What can we conclude from these results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "ejM1lRelImcM",
    "outputId": "39250637-340f-4f5b-9486-5f6444bacb33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'N [LOG]')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(6,4))\n",
    "ax.errorbar(l_N, py_mean_su, py_std_su, color='blue') \n",
    "ax.errorbar(l_N, njit_mean_su, njit_std_su, color='k') \n",
    "plt.loglog()\n",
    "plt.axhline(1, color='k', alpha=0.3, ls='--')\n",
    "ax.set_ylabel(\"Speedup [lOG]\", fontsize=14)\n",
    "ax.set_xlabel(\"N [LOG]\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvA3NDalFhuq"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5XF5ejNGV9k"
   },
   "source": [
    "# Section 2: Introduction to High-Performance Computing on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOT1hovjZJTM"
   },
   "source": [
    "## 2.1. What's a GPU?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7I1mIyWOXOt"
   },
   "source": [
    "![](imgs/slides_d2/065.PNG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJwvQvLjIXpB"
   },
   "source": [
    "+ It comes from **G**raphics **P**rocessing **U**nit.\n",
    "+ Specialized processor dedicated to graphics processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wd1qOCjoZbi9"
   },
   "source": [
    "## 2.2. Differences between CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODidwLZfZfZI"
   },
   "source": [
    "**CPU:** \n",
    "+ Multiple cores.\n",
    "+ Complex control logic.\n",
    "+ Optimized for serial operations.\n",
    "\n",
    "**GPU:** \n",
    "+ Many parallel executing units (ALUs).\n",
    "+ Best known use case: Graphics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBY4jRgcZzTL"
   },
   "source": [
    "## 2.3 Compute Unified Device Architecture (CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02fs-NOZZ6f5"
   },
   "source": [
    "### 2.3.1. What's CUDA?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zoljPgbOT6u"
   },
   "source": [
    "![](imgs/slides_d2/070.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ks6L4AHoI6US"
   },
   "source": [
    "+ Cuda is a software layer that gives direct access to the GPUâ€™s virtual instruction set and parallel computational elements to execute functions, called *kernels*.\n",
    "+ CUDA is indicated as a General-Purpose computing on GPUs (GPGPU).\n",
    "+ GPUs traditionally handle computations for computer graphics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLnmvf7RavdZ"
   },
   "source": [
    "### 2.3.2. CUDA's Program Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDkxnv0KOQOb"
   },
   "source": [
    "![](imgs/slides_d2/071.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hiWbJkHa4U7"
   },
   "source": [
    "1. Load data on Host.\n",
    "2. Allocate device memory.\n",
    "3. Copy data from Host to Device.\n",
    "4. Execute divece *kernels* to process data.\n",
    "5. Copy results from Device to Host memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XjJJ5iKbRED"
   },
   "source": [
    "## 2.4. Parallel GPU computing with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVtRkkmnbvOf"
   },
   "source": [
    "### 2.4.1. Universal functions (`ufunc`)\n",
    "\n",
    "A universal function is a function that operates on `ndarrays` in an element-by-element fashion, supporting array broadcasting, type casting, and several other standard features. \n",
    "\n",
    "A `ufunc` is a \"vectorized\" wrapper for a function that takes a fixed number of specific inputs and produces a fixed number of specific outputs. \n",
    "\n",
    "(_Source: [Numpy Documentation](https://numpy.org/doc/stable/reference/ufuncs.html)_)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVVnPlcZcYRM"
   },
   "source": [
    "#### 2.4.1.1. Example: My first vectorized function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ggpWB7GcfvL"
   },
   "outputs": [],
   "source": [
    "from numba import vectorize \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IrQNce9nbUlj"
   },
   "outputs": [],
   "source": [
    "# generating data\n",
    "num_points = int(1e6) # 1 million of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WnLINLgdckkg"
   },
   "outputs": [],
   "source": [
    "@vectorize\n",
    "def cpu_sqrt(x):\n",
    "    return math.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4MKax31wcmnD"
   },
   "outputs": [],
   "source": [
    "@vectorize(['float32(float32)'], target='cuda')\n",
    "def gpu_sqrt(x):\n",
    "    return math.sqrt(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPr0t0XodN0N"
   },
   "source": [
    "#### 2.4.1.2. Allowing multiple signatures in vectorized functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJl5wJqiK9Jz"
   },
   "source": [
    "Numba's vectorized functions can allow more than one data type as input. In that case, we will need to add another signature as the input parameter of the vectorize decorator.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IfSIatVMdQ9H"
   },
   "outputs": [],
   "source": [
    "@vectorize(['int32(int32, int32)', 'float64(float64, float64)'])\n",
    "def my_ufunc(x, y):\n",
    "    return x+y+math.sqrt(x*math.cos(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4H1miYPxeoxs"
   },
   "outputs": [],
   "source": [
    "@vectorize(['int32(int32, int32)', 'float64(float64, float64)'])\n",
    "def my_ufunc(x, y):\n",
    "    return np.abs(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ayKWy9pAdUA9",
    "outputId": "a3e230ea-3a03-4550-a81d-546a08fe4a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1.0, 10.0, dtype='f8')\n",
    "b = np.arange(1.1, 10.1, dtype='f8')\n",
    "print(my_ufunc(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv8svWxOdTM5",
    "outputId": "b7e91d81-dcf1-4273-b178-f1764873c8d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1, 10, dtype='i4')\n",
    "b = np.arange(2, 11, dtype='i4')\n",
    "print(my_ufunc(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpRPsiCXcsK6"
   },
   "source": [
    "#### 2.4.1.2. Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epwq91XHiD4w"
   },
   "source": [
    "Create two vectorized functions: `my_cpu_ufunc` and `my_gpu_func`. Both receive two arrays `x` and `y` as input parameters.\n",
    "\n",
    "Make `my_cpu_ufunc` and `my_gpu_ufunc` running in CPU and GPU, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_Sp0xn6cvx8"
   },
   "source": [
    "#### 2.4.1.3. Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urtaqyTJimPL"
   },
   "outputs": [],
   "source": [
    "from numba import vectorize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jd_Zpz_WiuAj"
   },
   "outputs": [],
   "source": [
    "# generating data\n",
    "a = np.arange(1.0, 10.0)\n",
    "b = np.ones(shape=a.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5XrUesxia2a"
   },
   "outputs": [],
   "source": [
    "# add the decorartor here!\n",
    "def my_cpu_ufunc(x, y):\n",
    "    return abs(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlBl6-rDieyD"
   },
   "outputs": [],
   "source": [
    "# add the decorartor here!\n",
    "def my_gpu_ufunc(x, y):\n",
    "    return abs(x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUv6LEtxjFwo"
   },
   "source": [
    "Try them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_59neYsio57",
    "outputId": "10d63479-aad0-46ec-c960-99ff02602bdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 Âµs, sys: 4 Âµs, total: 29 Âµs\n",
      "Wall time: 33.4 Âµs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_cpu_ufunc(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQz5MAwXi36k",
    "outputId": "7f7e599b-e1cf-4c44-8259-4d6ce3e297df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.34 ms, sys: 33 Âµs, total: 4.37 ms\n",
      "Wall time: 4.51 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_gpu_ufunc(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voMEhB-_jsjR"
   },
   "source": [
    "How was the performance of CPU vs GPU vectorization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1inNsKNNR8u"
   },
   "source": [
    "#### 2.4.1.3 Solution (Solved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9BouUkTgv3b"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XBXxiGCc7ME"
   },
   "outputs": [],
   "source": [
    "from numba import vectorize \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWF4kcbHc5sx"
   },
   "outputs": [],
   "source": [
    "@vectorize(['float64(float64, float64)'], target='cpu')\n",
    "def my_cpu_ufunc(x, y):\n",
    "    return abs(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PSoyCGE7giQC"
   },
   "outputs": [],
   "source": [
    "@vectorize(['float64(float64, float64)'], target='cuda')\n",
    "def my_gpu_ufunc(x, y):\n",
    "    return abs(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sz-cy60kc-4N"
   },
   "outputs": [],
   "source": [
    "a = np.arange(1.0, 10.0)\n",
    "b = np.ones(shape=a.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VKVIoYRmdAlM",
    "outputId": "6440148b-731c-4cf0-805d-41c3402c290c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6. 7. 8.]\n"
     ]
    }
   ],
   "source": [
    "# Calls compiled version of my_ufunc for each element of a and b\n",
    "print(my_cpu_ufunc(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mf5UQf9Pf9r4",
    "outputId": "b850d14a-19a2-43e8-cfb0-4389ce5a766c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6. 7. 8.]\n"
     ]
    }
   ],
   "source": [
    "# Calls compiled version of my_ufunc for each element of a and b\n",
    "print(my_gpu_ufunc(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a81YE7d-NWjR"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ckygt4ljbFu"
   },
   "source": [
    "## 2.4.2.  GPU's Device functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMSAbJ-BNgtF"
   },
   "source": [
    "### 2.4.2.1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9drHZ19Nlnl"
   },
   "source": [
    "Remember the CUDA program flow? We can have control of the data transfering of our data from/to GPU with GPU's device functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qNuapQWN95X"
   },
   "source": [
    "![](imgs/slides_d2/071.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFRV5zL2N-dK"
   },
   "source": [
    "These functions are compiled functoins executed on GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wqL_dwAZMlJ"
   },
   "source": [
    "### 2.4.2.2. Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdUf39j8Q1im"
   },
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8p-PAufPQxlN"
   },
   "outputs": [],
   "source": [
    "@vectorize(['int16(int16, int16)'], target='cuda')\n",
    "def a_device_function(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXLXEjs8RnJG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1f9OVMDRP-j",
    "outputId": "1de3a50f-efef-49db-aca3-3075311e8623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "[2 2 2 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "n = 10_000\n",
    "x = np.ones(shape=n, dtype=np.int16)\n",
    "y = x*2\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymQ9PuVERFu7"
   },
   "outputs": [],
   "source": [
    "# transfer inputs to the gpu\n",
    "x_gpu = cuda.to_device(x)\n",
    "y_gpu = cuda.to_device(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UBiZYEFPQyWC"
   },
   "outputs": [],
   "source": [
    "# creating out array on GPU\n",
    "z_gpu = cuda.device_array(shape=(n,), dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7iO7qL47QyqW",
    "outputId": "7a1dda42-dd59-4c5f-faf9-0f9a728593f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numba.cuda.cudadrv.devicearray.DeviceNDArray at 0x7f94f73de450>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_device_function(x_gpu, y_gpu, out=z_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmPlYh1GR2cF"
   },
   "outputs": [],
   "source": [
    "z = z_gpu.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3nw4wWXR5l0",
    "outputId": "c9b5ab6e-0f6c-435e-cf51-d8b7019e7503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-PgaTX-wBq_"
   },
   "source": [
    "Pure Numpy version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P26xXu7Vv8N5"
   },
   "outputs": [],
   "source": [
    "n = 5_000_000\n",
    "\n",
    "# random values between 0. and 255.\n",
    "greyscales = np.floor(np.random.uniform(0, 256, n).astype(np.float32))\n",
    "# random weights following a Gaussian distribution\n",
    "# centred on 0.5 and with width 0.1\n",
    "weights = np.random.normal(.5, .1, n).astype(np.float32)\n",
    "\n",
    "def normalize(grayscales):\n",
    "    return grayscales / 255\n",
    "\n",
    "def weigh(values, weights):\n",
    "    return values * weights\n",
    "        \n",
    "def activate(values):\n",
    "    return ( np.exp(values) - np.exp(-values) ) / \\\n",
    "            ( np.exp(values) + np.exp(-values) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TqGYqQt6wKH_",
    "outputId": "980f4171-f4f6-4b46-84d0-9268df8734de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 5: 52.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "normalized = normalize(greyscales)\n",
    "weighted = weigh(normalized, weights)\n",
    "activated = activate(weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XE9_XIY5wHfA"
   },
   "source": [
    "Parallel version for the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMWKbBd8wELP"
   },
   "outputs": [],
   "source": [
    "@vectorize(['float32(float32)'],target='cuda')\n",
    "def gpu_normalize(x):\n",
    "    return x / 255\n",
    "\n",
    "@vectorize(['float32(float32, float32)'],target='cuda')\n",
    "def gpu_weigh(x, w):\n",
    "    return x * w\n",
    "\n",
    "@vectorize(['float32(float32)'],target='cuda')\n",
    "def gpu_activate(x): \n",
    "    return ( math.exp(x) - math.exp(-x) ) / ( math.exp(x) + math.exp(-x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yh---WLvwO5q",
    "outputId": "873428dc-f5dd-4b4d-8610-43f54f9ca734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 13.52 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 5: 34.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "normalized = gpu_normalize(greyscales)\n",
    "weighted = gpu_weigh(normalized, weights)\n",
    "activated = gpu_activate(weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdabQ1rywpxK"
   },
   "source": [
    "\" That's already quite nice, we gained more than a factor of two!\n",
    "\n",
    "But we realize that we spend time transferring data back and forth between the host and the GPU for nothing:\n",
    "\n",
    "    transfer greyscales to the GPU\n",
    "    transfer normalized to the host, and then back to the GPU, together with weights\n",
    "    transfer weighted to the host, and then back to the GPU\n",
    "    transfer activated to the host\n",
    "\n",
    "Actually, we only need to:\n",
    "\n",
    "    transfer greyscales and weights to the GPU\n",
    "    retrieve activated\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CuLUWigaw6Kb"
   },
   "outputs": [],
   "source": [
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ae0UgAQPw4u6",
    "outputId": "0191a3b2-3e07-4e90-e4dc-213b1b834132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.9 ms, sys: 975 Âµs, total: 13.9 ms\n",
      "Wall time: 14.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create intermediate arrays on the GPU\n",
    "normalized_gpu = cuda.device_array(shape=(n,), dtype=np.float32)\n",
    "weighted_gpu = cuda.device_array(shape=(n,),  dtype=np.float32)\n",
    "\n",
    "# note that output device arrays are provided as arguments \n",
    "gpu_normalize(greyscales, out=normalized_gpu)\n",
    "gpu_weigh(normalized_gpu, weights, out=weighted_gpu)\n",
    "activated = gpu_activate(weighted_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTOAGHvVxCoe"
   },
   "source": [
    "\"Another important thing to know is that we can also take full control on the transfers to and from the GPU like this: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qw_QD2HXxBSy"
   },
   "outputs": [],
   "source": [
    "# transfer inputs to the gpu\n",
    "greyscales_gpu = cuda.to_device(greyscales)\n",
    "weights_gpu = cuda.to_device(weights)\n",
    "\n",
    "# create intermediate arrays and output array on the GPU\n",
    "normalized_gpu = cuda.device_array(shape=(n,), dtype=np.float32)\n",
    "weighted_gpu = cuda.device_array(shape=(n,) ,  dtype=np.float32)\n",
    "activated_gpu = cuda.device_array(shape=(n,), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmGCM-2_xJ4E",
    "outputId": "7503c2d1-1210-4b34-8070-03b4bdca4098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 5: 1.6 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gpu_normalize(greyscales_gpu, out=normalized_gpu)\n",
    "gpu_weigh(normalized_gpu, weights_gpu, out=weighted_gpu)\n",
    "gpu_activate(weighted_gpu, out=activated_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lVCofoBPxPcW",
    "outputId": "ef3cdf2b-26eb-4a3b-b4a9-4cd904b37841"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03589012, 0.39105397, 0.26380607, ..., 0.11930222, 0.10589294,\n",
       "       0.41564855], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activated = activated_gpu.copy_to_host()\n",
    "activated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGQzpOtHv6rJ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKVZNEzfPf75"
   },
   "source": [
    "\"\n",
    "Wait! We do not gain anything and the CPU version is actually faster! \n",
    "\n",
    "If the calculation is too simple, there is no use shipping our data to the GPU for fast parallel processing, if we are to wait so long for the data transfers to complete. In other words, most of the time is spent in the data transfers, and the GPU is basically useless.\n",
    "\n",
    "Let's see what happens with a more involved calculation. \n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZrckcclNSHN",
    "outputId": "370f7dfc-3496-4812-f06f-a0e3d885ee55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18369633,  0.00225783],\n",
       "       [ 0.05449148, -0.50737995],\n",
       "       [ 0.45961592,  0.96869206],\n",
       "       ...,\n",
       "       [-0.22614779,  0.37502873],\n",
       "       [-0.25419563, -0.9403678 ],\n",
       "       [ 0.41602236,  0.24622814]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## From cartesian to polar coordinates on the GPU (Change this exercise)\n",
    "\n",
    "points = np.random.multivariate_normal([0,0], [[1.,0.9], [0.9,1.]], 1000).astype(np.float32)\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "3wmmntnBRMS9",
    "outputId": "46240897-adab-4207-b3b4-5be74d8e3ea2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f726c2d4f10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(3,3)); plt.scatter(points[:,0], points[:,1], alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "6abwRgRXRR9w",
    "outputId": "3c751587-ffff-46be-ebde-a9b65bc3f2fb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta = np.arctan2(points[:,1], points[:,0]) \n",
    "_ = plt.hist(theta, bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtO9TtCsRmjY"
   },
   "outputs": [],
   "source": [
    "# \"Now let's try and perform the same calculation on the GPU. This time, we have two input values, and we define the function signature accordingly.\"\n",
    "\n",
    "@vectorize(['float32(float32, float32)'], target='cuda')\n",
    "def gpu_arctan2(y, x): \n",
    "    theta = math.atan2(y,x)\n",
    "    return theta\n",
    "\n",
    "@vectorize(['float32(float32, float32)'], target='cpu')\n",
    "def cpu_arctan2(y, x): \n",
    "    theta = math.atan2(y,x)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "4xlkUrFLR2ai",
    "outputId": "fe658da5-f6de-4956-8083-6834e15308bf"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-2811dabcd6c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_arctan2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m     39\u001b[0m                       \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCUDAUFuncMechanism\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/deviceufunc.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(cls, typemap, args, kws)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0many_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0mdev_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m                 \u001b[0mdevarys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mto_device\u001b[0;34m(self, hostary, stream)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhostary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhostary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36m_require_cuda_context\u001b[0;34m(*args, **kws)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/api.py\u001b[0m in \u001b[0;36mto_device\u001b[0;34m(obj, stream, copy, to)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevicearray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/cudadrv/devicearray.py\u001b[0m in \u001b[0;36mauto_device\u001b[0;34m(obj, stream, copy)\u001b[0m\n\u001b[1;32m    763\u001b[0m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                 subok=True)\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0msentry_contiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0mdevobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_array_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/cudadrv/devicearray.py\u001b[0m in \u001b[0;36msentry_contiguous\u001b[0;34m(ary)\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0mcore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'C_CONTIGUOUS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'F_CONTIGUOUS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrmsg_contiguous_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Array contains non-contiguous buffer and cannot be transferred as a single memory region. Please ensure contiguous buffer with numpy .ascontiguousarray()"
     ]
    }
   ],
   "source": [
    "theta = gpu_arctan2(points[:,1], points[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOMFIEqMR2cv"
   },
   "outputs": [],
   "source": [
    "x = np.ascontiguousarray(points[:,0]);\n",
    "y = np.ascontiguousarray(points[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROmRIGVnR2jV"
   },
   "outputs": [],
   "source": [
    "theta = gpu_arctan2(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "IfdamWY1SBvA",
    "outputId": "bd399da8-d978-4f48-fcf6-3ee86f352c4b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(theta, bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRvJBKt0SDZO"
   },
   "outputs": [],
   "source": [
    "# \"As a general rule, one should remember that CUDA operates on data buffers that are contiguous in memory, like a C array, or a numpy array before any slicing.\"\n",
    "\n",
    "# \"Now let's be a bit more ambitious, and compute theta for 10 million points:\"\n",
    "\n",
    "points = np.random.multivariate_normal([0,0], [[1.,0.9], [0.9,1.]], int(1e7)).astype(np.float32)\n",
    "x = np.ascontiguousarray(points[:,0])\n",
    "y = np.ascontiguousarray(points[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WTlBvqAjSkqP",
    "outputId": "59011dcd-81fc-4d33-ef54-0f1e91e6b37f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 5: 156 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit np.arctan(y, x) # numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0PMKhzjsS27x",
    "outputId": "9839eb9b-7f5a-4c23-bb61-0f463257897b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 5: 261 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit cpu_arctan2(y, x) # compiled for the CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DbQoUhWISy6k",
    "outputId": "38bfa12c-c0bd-4747-9ce7-ee31053b715b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 5: 30.6 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit gpu_arctan2(y, x) # compiled for the GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1yBb6_qTXZi",
    "outputId": "01427a4d-024f-4288-c4ed-347516518c73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 5: 5.62 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit [math.atan2(point[1], point[0]) for point in points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmOKCRcS-K_N"
   },
   "source": [
    "# Section 3: Graph analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7vyZP8b-ulK"
   },
   "source": [
    "**Context**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF6E6v-g-PeO"
   },
   "source": [
    "Historically first and conceptually simplest is degree centrality, which is defined as the number of links incident upon a node (i.e., the number of ties that a node has). The degree can be interpreted in terms of the immediate risk of a node for catching whatever is flowing through the network (such as a virus, or some information). In the case of a directed network (where ties have direction), we usually define two separate measures of degree centrality, namely indegree and outdegree. Accordingly, indegree is a count of the number of ties directed to the node and outdegree is the number of ties that the node directs to others. When ties are associated to some positive aspects such as friendship or collaboration, indegree is often interpreted as a form of popularity, and outdegree as gregariousness.\n",
    "\n",
    "The degree centrality of a vertex $v$ , for a given graph $G := ( V , E )$ with $| V |$ vertices and $| E |$ edges, is defined as:\n",
    "\n",
    "$DegreeCentrality(v) = deg(v)$.\n",
    "\n",
    "Source: [Wikipedia](https://en.wikipedia.org/wiki/Centrality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KVfMSVJf54v0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import prange, jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caY-UtX9-OxE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqYfwCLd53AC"
   },
   "outputs": [],
   "source": [
    "adj = np.array([\n",
    "  [0, 1, 0, 1, 1],\n",
    "  [1, 0, 0, 1, 0],\n",
    "  [0, 0, 0, 0, 1],\n",
    "  [1, 1, 0, 0, 1],\n",
    "  [1, 0, 1, 1, 0],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C42Pc6Gl7rdn",
    "outputId": "d70cb553-7821-4617-b980-5a18b5b03e0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(adj, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nudKjZ_E9PpP",
    "outputId": "b3dd5d32-97f3-4778-e424-b64fa515128f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 13.58 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 5: 3.71 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit np.sum(adj, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VruSIaR57Yg"
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True, parallel=True)\n",
    "def node_degrees(A):\n",
    "    B = np.zeros(shape=A.shape[0])\n",
    "    for i in prange(A.shape[0]):\n",
    "        B[i] += np.sum(A[i,:])\n",
    "    return B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-Ff8oNy73s-",
    "outputId": "66fc99f0-ce45-46d4-ab1b-2665c583c3cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 207215.06 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 5: 2.84 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit node_degrees(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TENmggn7JQf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ciXmiBjIbVH9"
   },
   "source": [
    "# Section 3: A hidden layer implementation for image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEmPWCOnFOJ_"
   },
   "source": [
    "## 3.1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHPWGZWkFJE9"
   },
   "source": [
    "![](https://miro.medium.com/max/1400/1*7aroEBBT6eKjARQEdY5dlQ.png)\n",
    "\n",
    "(_Image from [TowardDataScience.com](https://towardsdatascience.com/how-to-build-neural-network-from-scratch-d202b13d52c1)_)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UDeyxvKFSK2"
   },
   "source": [
    "Imagine you want to train a neural network for image processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0UaBOKEEKGm"
   },
   "source": [
    "A hidden layer in the network might have to do the following:\n",
    "\n",
    "+ Normalize greyscale values in the image (**input**)\n",
    "+ Weight them (`w`)\n",
    "+ Apply an activation function $f$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwKEb3-1Z3yq"
   },
   "source": [
    "You can send an array `x` to GPU by running:\n",
    "\n",
    "```python\n",
    "x_gpu = cuda.to_device(x)\n",
    "```\n",
    "\n",
    "In case you need to store intermediate results in intermediate arrays, you can create them as follows:\n",
    "\n",
    "```python\n",
    "intermediate_gpu = cuda.device_array(shape=(n,), dtype=np.float32)\n",
    "```\n",
    "\n",
    "As you saw, you will have to specify (1) the array size and (2) the data type. In this case, this _\"CUDA-array\"_ has size `n` and its type is `float32`.\n",
    "\n",
    "You can check more data types [here](https://numpy.org/doc/stable/user/basics.types.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvEPxAf1LzQj"
   },
   "source": [
    "The input vector $x$ represent a greyscale image. It contains values from 0 to 255. \n",
    "\n",
    "Thus, this problem can be solved in three steps:\n",
    "\n",
    "1. Normalizing gray scale vectors: $\\hat{x} = x / 255$ (normilazing grayscale vectors)\n",
    "\n",
    "2. Applying weights: $\\hat{w} = \\hat{x} \\cdot {w}$\n",
    "\n",
    "3. Computing an activation function $f(\\hat{w})$ such that: $f(\\hat{w}) = \\frac{e^\\hat{w} - e^\\hat{w}}{e^\\hat{w} + e^\\hat{w}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQvuLQSWPB_B"
   },
   "source": [
    "First, we need to create the grayscale vectors ($x$):\n",
    "\n",
    "Next, we will start the weights ($w$)of our network randomly, following a Gaussian distribution with $\\mu = 0.5$, and $\\sigma = 0.1$. Thus, such distribution is centred on 0.5 and with witdh 0.1.\n",
    "\n",
    "Both $x$ and $w$ with be defined as `np.float32`.\n",
    "\n",
    "The implementation with pure NumPy is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-owb3HCPEoP"
   },
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "\n",
    "# random values between 0. and 255.\n",
    "x = np.floor(np.random.uniform(0, 256, n).astype(np.float32))\n",
    "# random weights following a Gaussian distribution\n",
    "# centred on 0.5 and with width 0.1\n",
    "w = np.random.normal(.5, .1, n).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzRGS60qPHB3"
   },
   "source": [
    "And the proper computation of our activation function $f(\\hat{w})$ will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwboV6dkETAD"
   },
   "outputs": [],
   "source": [
    "def normalize(grayscales):\n",
    "    return grayscales / 255\n",
    "\n",
    "def weigh(values, weights):\n",
    "    return values * weights\n",
    "        \n",
    "def activate(values):\n",
    "    return ( np.exp(values) - np.exp(-values) ) / \\\n",
    "            ( np.exp(values) + np.exp(-values) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhHQXdPIEVk3"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "normalized = normalize(x)\n",
    "weighted = weigh(normalized, w)\n",
    "activated = activate(weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4IK5bL_EYI3"
   },
   "source": [
    "## 3.2. The Final Task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuOTET1SZx0L"
   },
   "source": [
    "## 3.2.1. Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnPr_vbYZ3yn"
   },
   "source": [
    "For this, we will need to import `cuda` from `numba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7czYJyqZ3yp"
   },
   "outputs": [],
   "source": [
    "from numba import cuda, vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR5NcSi8afz2"
   },
   "source": [
    "Then, we can generate some data for `greyscales` and start our network with random `weights`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zECkK-5Oaet3"
   },
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "\n",
    "# random values between 0. and 255.\n",
    "x = np.floor(np.random.uniform(0, 256, n).astype(np.float32))\n",
    "\n",
    "# random weights following a Gaussian distribution\n",
    "# centred on 0.5 and with width 0.2\n",
    "w = np.random.normal(.5, .2, n).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMf5hPVVaMIw"
   },
   "outputs": [],
   "source": [
    "# Hint: Transfer inputs to the GPU (i.e., x_gpu and w_gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hYCmJ-graHSL"
   },
   "outputs": [],
   "source": [
    "# Add a decorator to run it on GPU!\n",
    "def gpu_normalize(x):\n",
    "    return x / 255\n",
    "\n",
    "# Add a decorator to run it on GPU!\n",
    "def gpu_weigh(x, w):\n",
    "    return x * w\n",
    "\n",
    "# Add a decorator to run it on GPU!\n",
    "def gpu_activate(x): \n",
    "    return ( math.exp(x) - math.exp(-x) ) / ( math.exp(x) + math.exp(-x) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWxnj3iRZ3yr"
   },
   "source": [
    "Let's control the transfers to and from the GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDB8ChAAZ3ys"
   },
   "outputs": [],
   "source": [
    "# create intermediate arrays and output array on the GPU ('device array')\n",
    "# 1) normalized_gpu (shape=n, dtype=np.float32)\n",
    "# 2) weighted_gpu (shape=n, dtype=np.float32)\n",
    "# 3) activated_gpu (shape=n, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIX7wYxQbnYv"
   },
   "source": [
    "Do the computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tx9U_0PZ3yt"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "gpu_normalize(x_gpu, out=normalized_gpu)\n",
    "gpu_weigh(normalized_gpu, w_gpu, out=weighted_gpu)\n",
    "gpu_activate(weighted_gpu, out=activated_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xfnvko8ZZ3yv"
   },
   "source": [
    "Finally, we retrieve the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2uvWFVBZ3yz"
   },
   "outputs": [],
   "source": [
    "activated = activated_gpu.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jPsbtShbwwI"
   },
   "outputs": [],
   "source": [
    "print(activated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QulMzGhNbyx_"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kA2p1lsZb39k"
   },
   "source": [
    "## 3.2.1. [DELETE] Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eu-ZuLV7b39o"
   },
   "source": [
    "For this, we will need to import `cuda` from `numba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBZD33C1b39r"
   },
   "outputs": [],
   "source": [
    "from numba import cuda, vectorize\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alT5s4-Ub39u"
   },
   "source": [
    "Then, we can generate some data for `greyscales` and start our network with random `weights`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5UDO8tpb39w"
   },
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "\n",
    "# random values between 0. and 255.\n",
    "x = np.floor(np.random.uniform(0, 256, n).astype(np.float32))\n",
    "\n",
    "# random weights following a Gaussian distribution\n",
    "# centred on 0.5 and with width 0.2\n",
    "w = np.random.normal(.5, .2, n).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13m9nC0qb39y"
   },
   "outputs": [],
   "source": [
    "# Hint: Transfer inputs to the GPU (i.e., greyscales_gpu and weights_gpu)\n",
    "# transfer inputs to the gpu\n",
    "x_gpu = cuda.to_device(x)\n",
    "w_gpu = cuda.to_device(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xryIlh1ucIWA"
   },
   "outputs": [],
   "source": [
    "normalized_gpu = cuda.device_array(shape=(n,), dtype=np.float32)\n",
    "weighted_gpu = cuda.device_array(shape=(n,), dtype=np.float32)\n",
    "activated_gpu = cuda.device_array(shape=(n,), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tsz7ltxab390"
   },
   "outputs": [],
   "source": [
    "@vectorize(['float32(float32)'],target='cuda')\n",
    "def gpu_normalize(x):\n",
    "    return x / 255\n",
    "\n",
    "@vectorize(['float32(float32, float32)'],target='cuda')\n",
    "def gpu_weigh(x, w):\n",
    "    return x * w\n",
    "\n",
    "@vectorize(['float32(float32)'],target='cuda')\n",
    "def gpu_activate(x): \n",
    "    return ( math.exp(x) - math.exp(-x) ) / ( math.exp(x) + math.exp(-x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HWRWe7hUb394",
    "outputId": "7a8c0d36-e5ab-48b5-cd98-1c78e196a180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 433.18 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 5: 1.44 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gpu_normalize(x_gpu, out=normalized_gpu)\n",
    "gpu_weigh(normalized_gpu, w_gpu, out=weighted_gpu)\n",
    "gpu_activate(weighted_gpu, out=activated_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UObCoIBtb395"
   },
   "source": [
    "Finally, we retrieve the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LP26Nc3Ab396"
   },
   "outputs": [],
   "source": [
    "activated = activated_gpu.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NDKg822b397",
    "outputId": "d3b32270-1523-4a59-e6f7-5cafab3e2235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43143082 0.439002   0.03473125 ... 0.10591199 0.01777428 0.5020245 ]\n"
     ]
    }
   ],
   "source": [
    "print(activated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dn3QhTBcKGX1"
   },
   "source": [
    "### 3.2.1. Part 1. Using the GPU decorator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Csp9Dn9xKFl8"
   },
   "source": [
    "\n",
    "Implement a pararllel version of this algorithm on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vurk_W2Fhs3"
   },
   "outputs": [],
   "source": [
    "# Add a decorator to run it on GPU!\n",
    "def gpu_normalize(x):\n",
    "    return x / 255\n",
    "\n",
    "# Add a decorator to run it on GPU!\n",
    "def gpu_weigh(x, w):\n",
    "    return x * w\n",
    "\n",
    "# Add a decorator to run it on GPU!\n",
    "def gpu_activate(x): \n",
    "    return ( math.exp(x) - math.exp(-x) ) / ( math.exp(x) + math.exp(-x) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onpT790OEdl9"
   },
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1T0E8I0Eev9"
   },
   "outputs": [],
   "source": [
    "@vectorize(['float32(float32)'],target='cuda')\n",
    "def gpu_normalize(x):\n",
    "    return x / 255\n",
    "\n",
    "@vectorize(['float32(float32, float32)'],target='cuda')\n",
    "def gpu_weigh(x, w):\n",
    "    return x * w\n",
    "\n",
    "@vectorize(['float32(float32)'],target='cuda')\n",
    "def gpu_activate(x): \n",
    "    return ( math.exp(x) - math.exp(-x) ) / ( math.exp(x) + math.exp(-x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UrX4QvjEg-v"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "normalized = gpu_normalize(greyscales)\n",
    "weighted = gpu_weigh(normalized, weights)\n",
    "activated = gpu_activate(weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhvQNR7rElWU"
   },
   "source": [
    "\n",
    "\n",
    "That's already quite nice, we gained more than a factor of two!\n",
    "\n",
    "But we realize that we spend time transferring data back and forth between the host and the GPU for nothing:\n",
    "\n",
    "    transfer greyscales to the GPU\n",
    "    transfer normalized to the host, and then back to the GPU, together with weights\n",
    "    transfer weighted to the host, and then back to the GPU\n",
    "    transfer activated to the host\n",
    "\n",
    "Actually, we only need to:\n",
    "\n",
    "    transfer greyscales and weights to the GPU\n",
    "    retrieve activated\n",
    "\n",
    "So let's do that:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxVQ_sseEh31"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# create intermediate arrays on the GPU\n",
    "normalized_gpu = cuda.device_array(shape=(n,), \n",
    "                               dtype=np.float32)\n",
    "weighted_gpu = cuda.device_array(shape=(n,), \n",
    "                             dtype=np.float32)\n",
    "\n",
    "# note that output device arrays are provided as arguments \n",
    "gpu_normalize(x_gpu, out=normalized_gpu)\n",
    "gpu_weigh(normalized_gpu, w_gpu, out=weighted_gpu)\n",
    "activated = gpu_activate(weighted_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqmNxJ46KQbl"
   },
   "source": [
    "### 3.2.1. Part 2. Controlling data transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPMuRdjzZs1z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIblYBFxKmpF"
   },
   "source": [
    "For this, we will need to import `cuda` from `numba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2jmrBceKrbN"
   },
   "outputs": [],
   "source": [
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5rt76SKKaVX"
   },
   "source": [
    "You can send an array `x` to GPU by running:\n",
    "\n",
    "```python\n",
    "x_gpu = cuda.to_device(x)\n",
    "```\n",
    "\n",
    "In case you need to store intermediate results in intermediate arrays, you can create them as follows:\n",
    "\n",
    "```python\n",
    "intermediate_gpu = cuda.device_array(shape=(n,), dtype=np.float32)\n",
    "```\n",
    "\n",
    "As you saw, you will have to specify (1) the array size and (2) the data type. In this case, this _\"CUDA-array\"_ has size `n` and its type is `float32`.\n",
    "\n",
    "You can check more data types [here](https://numpy.org/doc/stable/user/basics.types.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "611Wg2PIEqsm"
   },
   "source": [
    "Let's control the transfers to and from the GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEK2hcFTEpIB"
   },
   "outputs": [],
   "source": [
    "# transfer inputs to the gpu\n",
    "greyscales_gpu = cuda.to_device(greyscales)\n",
    "weights_gpu = cuda.to_device(weights)\n",
    "\n",
    "# create intermediate arrays and output array on the GPU\n",
    "normalized_gpu = cuda.device_array(shape=(n,), \n",
    "                               dtype=np.float32)\n",
    "weighted_gpu = cuda.device_array(shape=(n,), \n",
    "                             dtype=np.float32)\n",
    "activated_gpu = cuda.device_array(shape=(n,), \n",
    "                             dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SW_ApBg_EzwA"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "gpu_normalize(greyscales_gpu, out=normalized_gpu)\n",
    "gpu_weigh(normalized_gpu, weights_gpu, out=weighted_gpu)\n",
    "gpu_activate(weighted_gpu, out=activated_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXEbuc4SE1r9"
   },
   "source": [
    "Finally, we retrieve the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNuk30-0E0Y1"
   },
   "outputs": [],
   "source": [
    "activated = activated_gpu.copy_to_host()\n",
    "activated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeJ3q-CIJo3x"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGJfhs2-zDzX"
   },
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-wXnSxkzIj_"
   },
   "source": [
    "## I. Scientific articles and books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4W2Al36ZzIeN"
   },
   "source": [
    "+ Navarro, C. A., Hitschfeld-Kahler, N., & Mateu, L. (2014). A survey on parallel computing and its applications in data-parallel problems using GPU architectures. Communications in Computational Physics, 15(2), 285-329. DOI: [10.1.1.958.9741](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.958.9741&rep=rep1&type=pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwl6FQIVzzAg"
   },
   "source": [
    "## II. Web Tutorials, blogs and articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0vp2qKMzIOV"
   },
   "source": [
    "+ Numba: A High Performance Python Compiler. https://numba.readthedocs.io/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8GBK4EI0AGV"
   },
   "source": [
    "## III. Web images and icons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YdkDZR80Gu1"
   },
   "source": [
    "+ Fiylo. http://www.fiylo.de\n",
    "+ Syracuse University web-platform. Kid-Friendly Coding Languages and Learning Tools. https://onlinegrad.syracuse.edu/blog/kid-friendly-coding-languages/.\n",
    "+ TheValuable.de. Difference between compiler and interpreter. https://thevaluable.dev/difference-between-compiler-interpreter/.\n",
    "+ Jack Daniel. Medium. Data Preprocessing in Machine Learning Model. https://medium.com/analytics-vidhya/data-preprocessing-in-machine-learning-model-3af34d0f3ceb. \n",
    "+ MyMasterDesigner.com. Exploratory data analysis (EDA) with Python. https://mymasterdesigner.com/2021/05/30/exploratory-data-analysis-eda-with-python/. \n",
    "+ FlatIcon (https://www.flaticon.com/). (Awesome webpage with free download icons ðŸ–¤).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZogGqAW6JS3"
   },
   "source": [
    "## IV. Additional Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHXooj49K12T"
   },
   "source": [
    "+ Sundnes, J. (2020). Introduction to Scientific Programming with Python (p. 148). Springer Nature. DOI: [10.1007/978-3-030-50356-7](https://doi.org/10.1007/978-3-030-50356-7).\n",
    "+ Stephen Fordham, \"How to use decorators in python by example\". Towards Data Science. https://towardsdatascience.com/how-to-use-decorators-in-python-by-example-b398328163b.\n",
    "\n",
    "+ Teclado ([Youtube channel](https://www.youtube.com/channel/UCINg1S61mpN7dZW8vR2ikCw)).\n",
    "+ Python exercises. w3resourse. [https://www.w3resource.com/python-exercises/](https://www.w3resource.com/python-exercises/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JZcx5jK0st3"
   },
   "source": [
    "----\n",
    "\n",
    "Day #1 of the summer course \"_Introduction to High-Performance Computing in Python for Scientists!_\". \n",
    "\n",
    "\n",
    "[Goethe Research Academy for Early Career Researchers (GRADE)](https://www.goethe-university-frankfurt.de/), Goethe University Frankfurt, Germany. June 2022.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJ7mgYBMhRMW"
   },
   "source": [
    "# Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgfP-b7olP7Z"
   },
   "source": [
    "#### Installing Numba + CUDA on Google Colab!\n",
    "\n",
    "`(src=https://thedatafrog.com/en/articles/boost-python-gpu/)`\n",
    "\n",
    "We need to add two libraries: `libdevice` and `libnvvm.so`.\n",
    "\n",
    "In order to find it we nee to run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ud875YEtJVqE",
    "outputId": "b8298142-a374-4c99-b2e6-274cdccbf96e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/jaxlib/cuda/nvvm/libdevice\n",
      "/usr/local/cuda-11.0/nvvm/libdevice\n",
      "/usr/local/cuda-11.1/nvvm/libdevice\n",
      "/usr/local/cuda-10.0/nvvm/libdevice\n",
      "/usr/local/cuda-10.1/nvvm/libdevice\n",
      "find: â€˜/proc/34/task/34/netâ€™: Invalid argument\n",
      "find: â€˜/proc/34/netâ€™: Invalid argument\n"
     ]
    }
   ],
   "source": [
    "!find / -iname 'libdevice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ApKCGqXUJVss",
    "outputId": "99401a31-7e3e-4d53-e26c-40feae19e5b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-11.0/nvvm/lib64/libnvvm.so\n",
      "/usr/local/cuda-11.1/nvvm/lib64/libnvvm.so\n",
      "/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\n",
      "/usr/local/cuda-10.1/nvvm/lib64/libnvvm.so\n",
      "find: â€˜/proc/34/task/34/netâ€™: Invalid argument\n",
      "find: â€˜/proc/34/netâ€™: Invalid argument\n"
     ]
    }
   ],
   "source": [
    "!find / -iname 'libnvvm.so'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AgPcnUWlZhY"
   },
   "source": [
    "Finally, execute the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4EYfDnOJVx6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/local/lib/python3.7/dist-packages/jaxlib/cuda/nvvm/libdevice\"\n",
    "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvgC4XWO1zH3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TCR-HPC-D2_github  -  Introduction to HPC and applications in Python.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
